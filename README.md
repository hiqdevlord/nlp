# NLP - Tutorial
Coding for NLP hands-on sample
- NLP Preprocessing
	- Part 1: Word Tokenization [Medium](https://medium.com/@makcedward/nlp-pipeline-word-tokenization-part-1-4b2b547e6a3) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-word_tokenization.ipynb)
	- Part 2: Part of Speech [Medium](https://medium.com/@makcedward/nlp-pipeline-part-of-speech-part-2-b683c90e327d) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-part_of_speech.ipynb)
	- Part 3: Lemmatization [Medium](https://medium.com/@makcedward/nlp-pipeline-lemmatization-part-3-4bfd7304957) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp_lemmatization.ipynb)
	- Part 4: Stemming [Medium](https://medium.com/@makcedward/nlp-pipeline-stemming-part-4-b60a319fd52) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-stemming.ipynb)
	- Part 5: Stop Words [Medium](https://medium.com/@makcedward/nlp-pipeline-stop-words-part-5-d6770df8a936) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-stop_words.ipynb)
	- Part 6: Sentence Tokenization [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-sentence_tokenization.ipynb)
	- Part 7: Phrase Word Recognition
- Infomration Extraction
	- Regular Expression
	- Dictionary Recognition
	- Named Entity Recognition (NER) [Medium](https://medium.com/@makcedward/named-entity-recognition-3fad3f53c91e) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-named_entity_recognition.ipynb)
- Text Summarization
	- Extractive Approach [Medium](https://medium.com/@makcedward/text-summarization-extractive-approach-567fe4b85c23) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-text_summarization_extractive.ipynb)
	- Abstractive Approach
- Distance Measurement
	- Euclidean Distance, Cosine Similarity and Jaccard Index
	- Edit Distance
	- Word Mover's Distance (WMD)
- Word as a Feature
	- Bag of Word (BoW)
	- Term Frequency-Inverse Document Frequency (TF-IDF)
- Vector Representation
	- Character Embedding [Medium](https://medium.com/@makcedward/besides-word-embedding-why-you-need-to-know-character-embedding-6096a34a3b10) [Github](https://github.com/makcedward/nlp/blob/master/sample/nlp-character_embedding.ipynb)
	- Word2Vec (word2vec)
	- Negative Sampling
	- Global Vectors for Word Representation (GloVe)
	- fastText
	- Doc2Vec (doc2vec)
	- Context Vectors (CoVe)
- Others
	- Negative Sampling and Hierarchical Softmax